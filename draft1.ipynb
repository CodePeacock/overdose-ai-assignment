{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Cleaning and Preprocessing\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data from Excel file\n",
    "data = pd.read_excel(\"daily_offers.xlsx\")\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Replace missing values with median\n",
    "data.fillna(data.median(), inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Normalize data\n",
    "data = (data - data.mean()) / data.std()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Explatory Data Analysis\"\"\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatterplot of two variables\n",
    "sns.scatterplot(x=\"age\", y=\"income\", data=data)\n",
    "plt.show()\n",
    "\n",
    "# Histogram of a variable\n",
    "sns.histplot(x=\"income\", data=data)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of a variable\n",
    "sns.boxplot(x=\"education\", y=\"income\", data=data)\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix of all variables\n",
    "sns.heatmap(data.corr(), annot=True)\n",
    "plt.show()\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Feature Engineering\"\"\"\n",
    "\n",
    "# Create dummy variables for categorical variable\n",
    "data = pd.get_dummies(data, columns=[\"education\"])\n",
    "\n",
    "# Create interaction term between two variables\n",
    "data[\"age_income_interaction\"] = data[\"age\"] * data[\"income\"]\n",
    "\n",
    "# Scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[[\"age\", \"income\"]] = scaler.fit_transform(data[[\"age\", \"income\"]])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Feature Selection\"\"\"\n",
    "# Perform ANOVA test to select features\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "for feature in data.columns:\n",
    "    if feature != \"target\":\n",
    "        f, p = f_oneway(\n",
    "            data[data[\"target\"] == 0][feature], data[data[\"target\"] == 1][feature]\n",
    "        )\n",
    "        if p < 0.05:\n",
    "            print(f\"Significant feature: {feature}\")\n",
    "\n",
    "# Perform LASSO regression to select features\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "lasso = LassoCV(cv=5).fit(X, y)\n",
    "coef = pd.Series(lasso.coef_, index=X.columns)\n",
    "print(f\"Lasso selected {sum(coef != 0)} features\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Regression Model\"\"\"\n",
    "# Fit linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "model = LinearRegression().fit(X, y)\n",
    "\n",
    "# Fit logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "model = LogisticRegression().fit(X, y)\n",
    "\n",
    "# Fit random forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "model = RandomForestRegressor().fit(X, y)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model Evaluation\"\"\"\n",
    "# Evaluate linear regression model\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "print(f\"R-squared: {r2_score(y, y_pred)}\")\n",
    "print(f\"Mean squared error: {mean_squared_error(y, y_pred)}\")\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y, y_pred)}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate logistic regression model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred)}\")\n",
    "print(f\"Confusion matrix: {confusion_matrix(y, y_pred)}\")\n",
    "print(f\"Classification report: {classification_report(y, y_pred)}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate random forest regression model\"\"\"\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "print(f\"R-squared: {r2_score(y, y_pred)}\")\n",
    "print(f\"Mean squared error: {mean_squared_error(y, y_pred)}\")\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y, y_pred)}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize Residuals\"\"\"\n",
    "sns.scatterplot(x=y_pred, y=y - y_pred)\n",
    "plt.show()\n",
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}